{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import imaplib\n",
    "import email\n",
    "import os\n",
    "import pandas as pd\n",
    "import smtplib\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import time\n",
    "import openpyxl \n",
    "import docx\n",
    "import PyPDF2\n",
    "import pytesseract\n",
    "import textract\n",
    "from pytesseract import image_to_string\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as EN_STOP_WORDS\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as FR_STOP_WORDS\n",
    "from langdetect import detect\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.base import MIMEBase\n",
    "from email import encoders\n",
    "\n",
    "\n",
    "# Load spaCy's language models for English and French\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "nlp_fr = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "import yaml  #To load saved login credentials from a yaml file\n",
    "\n",
    "with open(\"C:/Users/khalil/PycharmProjects/pythonProject1/credentials.yml\") as f:\n",
    "    content = f.read()\n",
    "    \n",
    "# from credentials.yml import user name and password\n",
    "my_credentials = yaml.load(content, Loader=yaml.FullLoader)\n",
    "\n",
    "#Load the credentials data from yaml file\n",
    "time_frequency= my_credentials[\"time_frequency\"]\n",
    "FOLDER_PATH= r'C:/Users/khalil/Downloads/pdf/'\n",
    "EMAIL_ADDRESS = my_credentials[\"EMAIL_ADDRESS\"]\n",
    "EMAIL_PASSWORD = my_credentials[\"EMAIL_PASSWORD\"]\n",
    "IMAP_URL = 'imap.gmail.com'\n",
    "\n",
    "# Email configuration\n",
    "SMTP_SERVER = 'smtp.gmail.com'\n",
    "SMTP_PORT = 587\n",
    "SMTP_USERNAME = 'khalil.trabelsi@esprit.tn'\n",
    "SMTP_PASSWORD = 'wsqrfdbgsivgsqmu'\n",
    "RECIPIENT_EMAIL = 'khalil.trabelsi@esprit.tn'\n",
    "EMAIL_SUBJECT = 'Updated Excel File'\n",
    "EMAIL_BODY = 'Please find the updated Excel file attached.'\n",
    "# File to attach\n",
    "EXCEL_FILE_PATH = 'Stages_DataSet.xlsx'\n",
    "\n",
    "def extract_text_from_docx(docx_file):\n",
    "    doc = docx.Document(docx_file)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    with open(pdf_file, \"rb\") as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        full_text = []\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            full_text.append(page.extract_text())\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "def extract_text_from_image(image_file):\n",
    "    image = Image.open(image_file)\n",
    "    text=image_to_string(image)\n",
    "    return text\n",
    "def extract_text_from_excel(excel_file):\n",
    "    # Open the Excel workbook\n",
    "    workbook = openpyxl.load_workbook(excel_file)\n",
    "    \n",
    "    # Initialize a variable to store extracted text\n",
    "    extracted_text = \"\"\n",
    "    \n",
    "    # Loop through all sheets in the workbook\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        sheet = workbook[sheet_name]\n",
    "        \n",
    "        # Loop through all cells in the sheet and extract text\n",
    "        for row in sheet.iter_rows(values_only=True):\n",
    "            for cell_value in row:\n",
    "                if cell_value:\n",
    "                    extracted_text += str(cell_value) + \"\\n\"\n",
    "    \n",
    "    return extracted_text\n",
    "\n",
    "# Function to update the \"Attachment Text\" column with extracted text from attachments\n",
    "\n",
    "def update_attachment_text(row):\n",
    "    attachment_path = row[\"Attachment\"]\n",
    "    \n",
    "    # Check if the attachment path is a string, if not, return \"No attachment\"\n",
    "    if not isinstance(attachment_path, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Process the attachment text if the path is valid\n",
    "    if attachment_path.endswith(\".docx\"):\n",
    "        attachment_text = extract_text_from_docx(attachment_path)\n",
    "    elif attachment_path.endswith(\".pdf\"):\n",
    "        attachment_text = extract_text_from_pdf(attachment_path)\n",
    "    elif attachment_path.endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\")):\n",
    "        attachment_text = extract_text_from_image(attachment_path)\n",
    "    elif attachment_path.endswith((\".xls\", \".xlsx\")):\n",
    "        attachment_text = extract_text_from_excel(attachment_path)  # Call the Excel extraction function\n",
    "   \n",
    "    else:\n",
    "        # For other unsupported formats, use textract\n",
    "        try:\n",
    "            attachment_text = textract.process(attachment_path, encoding='utf-8', errors='ignore').decode(\"utf-8\", errors=\"ignore\")\n",
    "        except Exception as e:\n",
    "            attachment_text = \"\"\n",
    "    \n",
    "    return attachment_text\n",
    "# Function Combine text from attachments and body\n",
    "def Combine_text(row):\n",
    "    subject= row[\"Subject\"]\n",
    "    attachment_text = row[\"Attachment Text\"]\n",
    "    body_text= row[\"Body\"]\n",
    "    \n",
    "    # Combine and clean the extracted text from attachments and body\n",
    "    processed_text = f\"{subject}\\n\\n{body_text}\\n\\n{attachment_text}\".strip()\n",
    "    return processed_text\n",
    "def replace_french_unicode_escapes(input_string):\n",
    "    # Define a regular expression pattern to match French Unicode escapes.\n",
    "    french_unicode_pattern = r'\\\\u([0-9a-fA-F]{4})'\n",
    "\n",
    "    # Define a function to replace matched escapes with their corresponding characters.\n",
    "    def replace_unicode(match):\n",
    "        return chr(int(match.group(1), 16))\n",
    "\n",
    "    # Use re.sub to find and replace Unicode escapes.\n",
    "    result = re.sub(french_unicode_pattern, replace_unicode, input_string)\n",
    "    \n",
    "    return result\n",
    "# Function to perform text preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # lowercase\n",
    "    text = replace_french_unicode_escapes(text)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                           u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                           u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                           u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                           u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                           u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                           u\"\\U0001F000-\\U0001F0FF\"  # Miscellaneous Symbols and Pictographs\n",
    "                           u\"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "                           u\"\\U000024C2-\\U0001F251\"  # Enclosed Characters\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    # Detect language\n",
    "    try:\n",
    "        language = detect(text)\n",
    "    except:\n",
    "        language = None\n",
    "\n",
    "    # Choose the appropriate spaCy model based on the language\n",
    "    if language == 'en':\n",
    "        nlp = nlp_en\n",
    "        stop_words = EN_STOP_WORDS\n",
    "    elif language == 'fr':\n",
    "        nlp = nlp_fr\n",
    "        stop_words = FR_STOP_WORDS\n",
    "    else:\n",
    "        # Default to french if language detection fails or language is not supported\n",
    "        nlp = nlp_fr\n",
    "        stop_words = EN_STOP_WORDS\n",
    "\n",
    "#     # Tokenization, lowercasing, and lemmatization\n",
    "#     doc = nlp(text)\n",
    "#     words = [token.lemma_.lower() for token in doc]\n",
    "\n",
    "#     # Remove stopwords\n",
    "#     words = [word for word in words if word not in stop_words]\n",
    "\n",
    "#     # Join the preprocessed words back into a single string\n",
    "#     preprocessed_text = ' '.join(words)\n",
    "\n",
    "    return text, language\n",
    "def extract_information(text):\n",
    "    emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
    "    if emails:\n",
    "        emails = emails[0]\n",
    "    else:\n",
    "        emails = \"\"\n",
    "    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "    phone_numbers= re.findall(r'(\\+216[-.\\s]?\\d{2}[-.\\s]?\\d{3}[-.\\s]?\\d{3}|\\+216\\d{8}|\\b\\d{8}\\b|\\b\\d{2}[-\\s]?\\d{3}[-\\s]?\\d{3}\\b)', text)\n",
    "    return emails, urls,phone_numbers\n",
    "programming_keywords = [\"bi\", \"react native\", \"react js\", \"swagger\", \"intégration d'apis prédéveloppées\", \".net\", \"ai\", \"iot\", \"ansible\", \"aws\", \"adobe xd\", \"agile\", \"anaconda\", \"analyste de données sénior\", \"analytics\", \"android\",\"apex\", \"arango db\", \"archimate\", \"architecture micro-services\", \"azure\", \"bi tools\", \"bi business intelligence\", \"bmc\", \"bpmn\", \"bases de données relationnelles\", \"beautiful soup\", \"big data\", \"javascript\", \"html\", \"css\", \"business plan\", \"business intelligence\", \"c#\", \"ci/cd\", \"css\", \"travailler en équipe\", \"communiquer efficacement\", \"chatter bot\", \"cloud\", \"collaboration\", \"communication\", \"communication verbale et écrite\", \"problèmes inversés\", \"conception de logiciels\", \"odoo\", \"react\", \"angular\", \"vue.js\", \"architecture des systèmes d'information\", \"marketing\", \"créativité\", \"dax\", \"devops\", \"data analysis\", \"data analyst\", \"database management\", \"deeplearning\", \"design\", \"digital marketing strategy\", \"digital marketing\", \"intégration sociale\", \"django\", \"docker\", \"développement web\", \"e-commerce\", \"eclipse\", \"elaborer des fiches de missions\", \"des fiches de contrôle\", \"expressjs\", \"expérience des stages\", \"travail en freelance\", \"figma\", \"facebook analytics\", \"bases de données relationnelles\", \"sql\", \"firebase\", \"flutter\", \"front-end development\", \"full-stack development\", \"fullstack developer\", \"git\", \"gitlab\", \"gestion de projet\", \"gimsi\", \"google ux design\", \"google analytics\", \"grafana\", \"heroku\", \"hibernate\", \"html\", \"ios\", \"imagination\", \"créativité\", \"intelligence artificielle\", \"intégration continue\", \"ionic\", \"ionic development\", \"java\", \"jee\", \"jira\", \"javascript\", \"jenkins\", \"k8s\", \"keycloak\", \"kotlin\", \"kubernetes\", \"suivi des clients\", \"problèmes d’électricité\", \"c++\", \"c\", \"leadership development\", \"lucene\", \"mean or mern stack\", \"machine learning\", \"maitrise des notions du clean code\", \"management\", \"marketing\", \"marketing digital\", \"marvel\", \"maven\", \"maîtrise des notions de modèle et méta-modèle\", \"meteorjs\", \"micro-service\", \"microsoft azure\", \"microsoft dynamics 365\", \"mobile development\", \"mongodb\", \"ms excel\", \"mysql\", \"méthodologies agiles\", \"nlp\", \"nestjs\", \"node\", \"nodejs\", \"node js\", \"node.js\", \"numpy\", \"oaf\", \"optimisation de référencement (seo)\", \"oracle bi\", \"oracle forms\", \"organisation\", \"pdf scrapping\", \"pestel\", \"pl/sql\", \"powerbi\", \"pandas\", \"planification\", \"postgresql\", \"postman\", \"powerbi\", \"powerblas business intelligence\", \"product owner\", \"product manager\", \"professional experience\", \"python\", \"backend\", \"django\", \"qa analyst\", \"qlik sense\", \"reactjs\", \"rest\", \"rest api\", \"rest apis\", \"react native\", \"react.js\", \"recommendation engine\", \"rest api\", \"rigueur\", \"résolution des problèmes informatiques\", \"résolution des problèmes inversés\", \"machine learning\", \"deep learning\", \"seo\", \"sgbd\", \"sql\", \"svn/git\", \"swot\", \"scikit-learn\", \"scrapy\", \"scrum\", \"service now\", \"software development\", \"spring\", \"spring boot\", \"strong programming skills\", \"symfony\", \"tableau desktop\", \"tableau desktop/mspowerbi\", \"tailwind\", \"talend\", \"task automation\", \"teaching experience\", \"data science\", \"automatic number plate recognition\", \"anpr\", \"license plate recognition\", \"computer vision\", \"data preprocessing\", \"image enhancement\", \"noise reduction\", \"optical character recognition\", \"ocr\", \"state-of-the-art\", \"travail en équipe\", \"trello\", \"typescript\", \"user experience\", \"vscode\", \"volunteering opportunities\", \"web culture\", \"web scrapping\", \"web development\", \"web load\", \"web services\", \"xml\", \"xml publisher\", \"xp\", \"analyse de données\", \"analyse statistique\", \"architectures micro-services\", \"communication\", \"community management\", \"conception & modélisation\", \"copyrighting\", \"application mobile\", \"travail collaboratif\", \"gestion de projet\", \"développement mobile\", \"eclipse\", \"esprit d’analyse\", \"gestion de projet\", \"git\", \"hibernate search\", \"infrastructure\", \"invision\", \"javascript\", \"json\", \"langage uml\", \"mathématiques appliquées en statistiques\", \"mathématiques\", \"statistiques\", \"méthodes agile\", \"méthodologie agile\", \"notions unix\", \"outlook\", \"pandas\", \"proto.io\", \"python\", \"pytorch\", \"re\", \"sketch\", \"sponsoring\", \"stratégies marketing\", \"tabula-py\", \"tensorflow\"]\n",
    "def extract_skills(text):\n",
    "    # Initialize an empty list to store extracted skills\n",
    "    skills = []\n",
    "    \n",
    "    # Convert text to lowercase for case-insensitive matching\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\s+', ' ', text).strip()  # Remove and double spaces\n",
    "    # Use regular expression to find matches with programming keywords\n",
    "    for keyword in programming_keywords:\n",
    "        if re.search(r'\\b' + re.escape(keyword) + r'\\b', text):\n",
    "            skills.append(keyword)\n",
    "def specific_nlp(text):\n",
    "     # Detect language\n",
    "    try:\n",
    "        language = detect(text)\n",
    "    except:\n",
    "        language = None\n",
    "    if language == 'en':\n",
    "        return nlp_en\n",
    "    elif language == 'fr':\n",
    "        return nlp_fr\n",
    "    else:\n",
    "        # Default to french if language is not supported\n",
    "        return nlp_fr\n",
    "def extract_named_entities(text):\n",
    "    nlp = specific_nlp(text)\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n",
    "    return skills\n",
    "def check_and_process_emails():\n",
    "    # try:\n",
    "        # Connect to the mailbox\n",
    "        mail = imaplib.IMAP4_SSL(IMAP_URL)\n",
    "        mail.login(EMAIL_ADDRESS, EMAIL_PASSWORD)\n",
    "        mail.select('Inbox')\n",
    "\n",
    "        # Search for emails\n",
    "        key = '(OR BODY \"stage\" BODY \"internship\")'\n",
    "        type, data = mail.search(None, key)\n",
    "\n",
    "        id_list = data[0].split() \n",
    "\n",
    "        msgs = []\n",
    "        mylist = []\n",
    "        \n",
    "        for num in data[0].split():    \n",
    "            type, data = mail.fetch(num, '(RFC822)' )\n",
    "            # email_message = email.message_from_string(data[0][1].decode('utf-8'))\n",
    "            # sender_name, sender_email = email.utils.parseaddr(email_message['from'])#my_msg\n",
    "            msgs.append(data)\n",
    "        \n",
    "        \n",
    "        \n",
    "        email_list = []  # List to store email information as dictionaries\n",
    "        \n",
    "        for msg in msgs[::-1]:\n",
    "            for response_part in msg:\n",
    "                if isinstance(response_part, tuple):\n",
    "                    email_message = email.message_from_bytes(response_part[1])\n",
    "                    sender_name, sender_email = email.utils.parseaddr(email_message['from'])\n",
    "            email_info = {\n",
    "                'Date': email_message['date'],\n",
    "                'SenderName': sender_name,\n",
    "                'SenderEmail': sender_email,\n",
    "                'Recipient': email_message['to'],\n",
    "                'Subject': email_message['subject'],\n",
    "                'Body': ''\n",
    "            }\n",
    "        # downloading attachments\n",
    "            for part in email_message.walk():\n",
    "                if part.get_content_type() == 'text/plain':\n",
    "                    email_info['Body'] = part.get_payload(decode=True).decode('utf-8')\n",
    "                # this part comes from the snipped I don't understand yet... \n",
    "                if part.get_content_maintype() == 'multipart':            \n",
    "                    continue\n",
    "                if part.get('Content-Disposition') is None:\n",
    "                    continue\n",
    "                fileName = part.get_filename()\n",
    "                fileName = fileName.replace('<','')\n",
    "                fileName = fileName.replace('>','')\n",
    "                fileName = fileName.replace('=?UTF-8?Q?','')\n",
    "                fileName = fileName.replace('=','')\n",
    "                fileName = fileName.replace('\\r\\n\\t','')\n",
    "                fileName = fileName.replace('?','')\n",
    "                print (num)\n",
    "                if num in mylist:\n",
    "                    pass\n",
    "                else:\n",
    "                    mylist.append(num)\n",
    "                if bool(fileName):\n",
    "                    sender = email_message['From']\n",
    "                    sender = sender.replace('<','')\n",
    "                    sender = sender.replace('>','')\n",
    "                    sender = sender.replace('=?UTF-8?Q?','')\n",
    "                    sender = sender.replace('=','')\n",
    "                    sender = sender.replace('?','')\n",
    "                    tpath = FOLDER_PATH + str(sender)\n",
    "                    Path(tpath).mkdir(parents=True, exist_ok=True)\n",
    "                    filePath = os.path.join(tpath, fileName)\n",
    "                    # Attempt to open the file, and handle any FileNotFoundError\n",
    "                    if not os.path.isfile(filePath) :\n",
    "                        fp = open(filePath, 'wb')\n",
    "                        fp.write(part.get_payload(decode=True))\n",
    "                        fp.close()\n",
    "                    email_info['Attachment'] = filePath\n",
    "                    subject = str(email_message).split(\"Subject: \", 1)[1].split(\"\\nTo:\", 1)[0]\n",
    "                    print('Downloaded \"{file}\" from email titled \"{subject}\".'.format(file=fileName, subject=subject))            \n",
    "            email_list.append(email_info)\n",
    "        for i in mylist:\n",
    "            mail.copy(i, 'INBOX.Processed')\n",
    "            mail.store(i, '+FLAGS', '\\\\Deleted')\n",
    "        mail.expunge()\n",
    "        json_file_path = 'emails_with_attachments_data.json'\n",
    "        \n",
    "        # Write the email_list to a JSON file\n",
    "        with open(json_file_path, 'w', encoding='utf-8') as jsonfile:\n",
    "            json.dump(email_list, jsonfile, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        print(\"Email data saved to emails_with_attachments_data.json.\")           \n",
    "        \n",
    "        \n",
    "# ############################################################print(\"Read data from the JSON file\")\n",
    "        with open(json_file_path, 'r', encoding='utf-8') as jsonfile:\n",
    "            email_list = json.load(jsonfile)\n",
    "# convert it to a DataFrame using pandas, \n",
    "        df = pd.DataFrame(email_list)\n",
    "# Extracting text from docx pdf image and excel\n",
    "        df[\"Attachment Text\"] = \"\"\n",
    "        df[\"Attachment Text\"] = df.apply(update_attachment_text, axis=1)\n",
    "        df[\"Text\"] = \"\"\n",
    "# Update the \"preprocessed_text\" column with extracted text from attachments and body\n",
    "        df[\"Text\"] = df.apply(Combine_text, axis=1) \n",
    "        df['preprocessed_text'], df['Language'] = zip(*df['Text'].apply(preprocess_text))\n",
    "        df['emails']= \"\"\n",
    "        df['urls']= \"\"\n",
    "# Apply information extraction to the 'preprocessed_text' column\n",
    "        df['emails'],df['urls'],df['phone_numbers']= zip(*df['preprocessed_text'].apply(extract_information))\n",
    "    # Apply the extract_skills function to the \"preprocessed_text\" column\n",
    "        df['Skills'] = df['preprocessed_text'].apply(extract_skills)\n",
    "        # df['Company Name'] = df['preprocessed_text'].apply(extract_company_name)\n",
    "        print(df)\n",
    "            # Update Excel file\n",
    "        df.to_excel(\"Stages_DataSet.xlsx\", index=False)\n",
    "            # Send email with updated Excel file\n",
    "        # Create a multipart message\n",
    "        message = MIMEMultipart()\n",
    "        message['From'] = SMTP_USERNAME\n",
    "        message['To'] = RECIPIENT_EMAIL\n",
    "        message['Subject'] = EMAIL_SUBJECT\n",
    "        message.attach(MIMEText(EMAIL_BODY, 'plain'))\n",
    "        \n",
    "        # Attach the Excel file\n",
    "        attachment = open(EXCEL_FILE_PATH, 'rb')\n",
    "        part = MIMEBase('application', 'octet-stream')\n",
    "        part.set_payload((attachment).read())\n",
    "        encoders.encode_base64(part)\n",
    "        part.add_header('Content-Disposition', \"attachment; filename= %s\" % EXCEL_FILE_PATH)\n",
    "        message.attach(part)\n",
    "\n",
    "# Connect to the SMTP server and send the email\n",
    "        try:\n",
    "            server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n",
    "            server.starttls()\n",
    "            server.login(SMTP_USERNAME, SMTP_PASSWORD)\n",
    "            text = message.as_string()\n",
    "            server.sendmail(SMTP_USERNAME, RECIPIENT_EMAIL, text)\n",
    "            server.quit()\n",
    "            print('Email sent successfully with attachment.')\n",
    "        except Exception as e:\n",
    "            print(f'Error sending email: {str(e)}')\n",
    "            # Move the email to a 'Processed' folder or mark it as read\n",
    "        mail.copy(num, 'INBOX.Processed')\n",
    "        mail.store(num, '+FLAGS', '\\\\Deleted')\n",
    "        \n",
    "        # Expunge deleted emails\n",
    "        mail.expunge()\n",
    "        \n",
    "    # except Exception as e:\n",
    "    #     # Handle exceptions, e.g., log errors\n",
    "    #     print(f\"Error: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        check_and_process_emails()\n",
    "        # Sleep for a period before checking again (e.g., every 5 minutes)\n",
    "        time.sleep(time_frequency)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "691f69381737a6a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
